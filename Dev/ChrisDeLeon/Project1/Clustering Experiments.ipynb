{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Detector.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import threading\n",
    "import os\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_like(file_name_pattern=r'(?s).*', folder=None):\n",
    "    \"\"\"\n",
    "    Returns a list of all files in `folder` with a name that matches\n",
    "    `file_name_pattern`.\n",
    "    \"\"\"\n",
    "    file_names = []\n",
    "    for file_name in os.listdir(folder):\n",
    "        if re.search(file_name_pattern, file_name):\n",
    "            file_names.append(os.path.join(folder, file_name))\n",
    "    return file_names\n",
    "                \n",
    "def load_data_from(file_names, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns the dataframe(s) associated with each file name in \n",
    "    `file_names`.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    if type(file_names) == str:\n",
    "        return pd.read_csv(file_names, **kwargs)\n",
    "    else:\n",
    "        for file_name in file_names:\n",
    "            data.append(pd.read_csv(file_name, **kwargs))      \n",
    "    return data[0] if len(data) == 1 else data\n",
    "\n",
    "def key_formatter(name):\n",
    "    \"\"\"\n",
    "    Reformats the names of the files for convenience.\n",
    "    \"\"\"\n",
    "    return name.split('_')[-1].split('.')[0]\n",
    "\n",
    "def run_experiments(locations, kernels, clusters, outputs=defaultdict(dict), *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns a nested dictionary, d, such that d[c][k] is the detector \n",
    "    used for kernel k with a clustering value of c.\n",
    "    \"\"\"\n",
    "    for c in clusters:\n",
    "        for n, k in kernels.items():\n",
    "            outputs[c][n] = Detector(k, locations, as_df=True, n_clusters=c, *args, **kwargs).run()\n",
    "        print('Completed cluster:', c)\n",
    "    return outputs\n",
    "\n",
    "def parallelize_experiments(locations, kernels, clusters, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Parallelizes the calls to run_experiments. The `clusters` parameter\n",
    "    is assumed to have the following format:\n",
    "    \n",
    "        clusters = [\n",
    "            [ ...cluster(s)... ],\n",
    "            [ ...cluster(s)... ],\n",
    "            ...\n",
    "            [ ...cluster(s)... ]\n",
    "        ]\n",
    "    \n",
    "    Each list of clusters will be processed by one thread.\n",
    "    \"\"\"\n",
    "    threads = []\n",
    "    outputs = defaultdict(dict)\n",
    "    for i, cluster in enumerate(clusters):\n",
    "        inputs = (locations, kernels, cluster, outputs, *args, )\n",
    "        threads.append(threading.Thread(target=run_experiments, name=f'thread {i}', args=inputs, kwargs=kwargs))\n",
    "        threads[i].start()\n",
    "\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "    \n",
    "    print(\"Done!\")\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KER_FOLDER = 'data/kernel1'\n",
    "LOC_FOLDER = 'data/locations'\n",
    "\n",
    "stp_loc = load_data_from(get_files_like('stp_cluster', LOC_FOLDER))\n",
    "kernels = {\n",
    "    key_formatter(f) : load_data_from(f, header=None) for f in get_files_like('kernel', KER_FOLDER)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stp_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify tolerance for bridge labeling and steady state detection\n",
    "b, s = 1e-2, 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment these lines to run experiments in series\n",
    "# clusters = [2, 3, 4, 5, 6, 7, 8, 9, 10, 50, 100, 150, 200, 250, 300]\n",
    "# results = run_experiments(stp_loc, kernels, clusters, b_tol=b, s_tol=s)\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment these lines to run experiments in parallel\n",
    "clusters = [\n",
    "    [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    [25, 75, 100],\n",
    "    [50, 150]\n",
    "]\n",
    "results = parallelize_experiments(stp_loc, kernels, clusters, b_tol=b, s_tol=s)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "\n",
    "def get_label_counts(results, cluster_num, kernel_names=None):\n",
    "    df = pd.DataFrame()\n",
    "    names = results[cluster_num].keys() if kernel_names is None else kernel_names\n",
    "    for name in names:\n",
    "        d = results[cluster_num][name]\n",
    "        counts = d.results().groupby('type').size().to_frame().rename(columns={0 : \"count\"})\n",
    "        if 'bridge' not in counts.index:\n",
    "            counts = counts.append(pd.DataFrame([0], index=['bridge'], columns=['count']))\n",
    "        if 'sink'   not in counts.index:\n",
    "            counts = counts.append(pd.DataFrame([0], index=['sink'], columns=['count']))\n",
    "        if 'source' not in counts.index:\n",
    "            counts = counts.append(pd.DataFrame([0], index=['source'], columns=['count']))\n",
    "        counts = pd.concat({name : counts}, names=['name'])\n",
    "        df = pd.concat([df, counts])\n",
    "    df['clusters'] = cluster_num\n",
    "    return df\n",
    "\n",
    "def get_steps(d, k, start=None, final=None):\n",
    "    if type(k) != int:\n",
    "        return k\n",
    "    elif start is None and final is None:\n",
    "        return np.round(np.linspace(0, d.ss_step, k)).astype(int)\n",
    "    elif start is None:\n",
    "        return np.round(np.linspace(0, final, k)).astype(int)\n",
    "    elif final is None:\n",
    "        return np.round(np.linspace(0, d.ss_step, k)).astype(int)\n",
    "    else:\n",
    "        return np.round(np.linspace(start, final, k)).astype(int)\n",
    "\n",
    "# Static Plots\n",
    "    \n",
    "def steady_state_lineplot(results, cluster_num, k=200, start=None, final=None, fs=(8,8)):\n",
    "    \"\"\"\n",
    "    Plots the number of nodes that experienced a population change \n",
    "    versus time over `k` evenly spaced values. A custom range may be\n",
    "    used if `k` is passed in as a list of ints.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    if final is None: final = np.max([d.ss_step for d in results[cluster_num].values()])\n",
    "    for n, d in results[cluster_num].items():\n",
    "        steps = get_steps(d, k, start, final)\n",
    "        temp = pd.DataFrame()\n",
    "        temp['count'] = np.sum(~np.isclose(np.diff(np.array([d.migrate(s) for s in steps]), axis=0), 0), axis=1)\n",
    "        temp['kname'] = n\n",
    "        temp['steps'] = steps[1:]\n",
    "        df = pd.concat([df, temp])\n",
    "    plt.figure(figsize=fs)\n",
    "    sns.lineplot(x=\"steps\", y=\"count\", hue=\"kname\", data=df)\n",
    "    plt.title(\"Steady State Progression\")\n",
    "    plt.xlabel(\"Time Step\")\n",
    "    plt.ylabel(\"Number of Migrations\")\n",
    "    \n",
    "def label_counts_barplot(results, cluster_num, fs=(8,6)):\n",
    "    \"\"\"\n",
    "    Plots a side by side bar plot of the sink/bridge/source counts\n",
    "    for each kernel.\n",
    "    \"\"\"\n",
    "    df = get_label_counts(results, cluster_num).reset_index().rename(columns={'level_1' : 'type'})\n",
    "    plt.figure(figsize=fs)\n",
    "    sns.barplot(x=\"name\", y=\"count\", hue=\"type\", data=df)\n",
    "    plt.title(f\"Sink/Bridge/Source Counts for {cluster_num} Cluster(s)\")\n",
    "    plt.xticks(rotation=30);\n",
    "\n",
    "def label_counts_lineplot(results, kernel_name, fs=(8,6)):\n",
    "    \"\"\"\n",
    "    Plots a lineplot of sink/bridge/source count versus clusters\n",
    "    for `kernel_name`.\n",
    "    \"\"\"\n",
    "    df = pd.concat([get_label_counts(results, c, [kernel_name]) for c in results])\\\n",
    "           .reset_index()\\\n",
    "           .rename(columns={'level_1' : 'type'})\n",
    "    plt.figure(figsize=fs)\n",
    "    sns.lineplot(x=\"clusters\", y=\"count\", hue=\"type\", data=df)\n",
    "    plt.title(f\"Sink/Bridge/Source Counts for {kernel_name} Cluster(s)\")\n",
    "    plt.xticks(rotation=30);\n",
    "\n",
    "# Interactive Plots\n",
    "    \n",
    "def plot_interactive_label_counts(results, kernel_name):\n",
    "    \"\"\"\n",
    "    Plots a side by side bar plot of the sink/bridge/source counts\n",
    "    for `kernel_name` over all clusters.\n",
    "    \"\"\"\n",
    "    df = pd.concat([get_label_counts(results, c, [kernel_name]) for c in results])\\\n",
    "           .reset_index()\\\n",
    "           .rename(columns={'level_1' : 'type'})\n",
    "    fig = px.bar(df, x=\"type\", y=\"count\", color=\"type\",\n",
    "      animation_frame=\"clusters\", animation_group=\"clusters\", range_y=[0, df[\"count\"].max()])\n",
    "    fig.show()\n",
    "    \n",
    "    \n",
    "def plot_population_distribution(results, cluster_num, kernel_name, k=200, start=None, final=None):\n",
    "    \"\"\"\n",
    "    Plots an interactive visualization of the population for every \n",
    "    state from time step `start` to time step `final` over `k` values\n",
    "    for `kernel_name`. A custom range may be used if `k` is passed in\n",
    "    as a list of ints.\n",
    "    \"\"\"\n",
    "    d = results[cluster_num][kernel_name]\n",
    "    steps = get_steps(d, k, start, final)        \n",
    "    df = pd.DataFrame({\n",
    "        'node'       : list(range(len(d.tmtx))) * len(steps),\n",
    "        'population' : np.array([d.migrate(s) for s in steps]).flatten(),\n",
    "        'step'       : np.array([[s] * len(d.tmtx) for s in steps]).flatten()\n",
    "    })\n",
    "    \n",
    "    fig = px.bar(df, x=\"node\", y=\"population\", color=\"node\",\n",
    "      animation_frame=\"step\", animation_group=\"node\", range_y=[0, df['population'].max()])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Kernels:\", list(kernels.keys()))\n",
    "print(\"Clusters:\", np.array(clusters).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a kernel name and a clustering number\n",
    "KERNEL_NAME = '2500'\n",
    "CLUSTER_NUM = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steady State Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steady_state_lineplot(results, CLUSTER_NUM, k=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_range = list(range(81)) + list(range(500, 1000, 50))\n",
    "plot_population_distribution(results, CLUSTER_NUM, KERNEL_NAME, k=custom_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation(s): \n",
    "- The time step at which steady state occurs appears to be longer as kernel number decreases.\n",
    "- The number of clusters do not interfere with the time step at which steady state occurs.\n",
    "- The population changes most drastically in the first hundred time steps. Very minor changes in population occur afterwards. This occurs for all combinations of kernels and clusters.\n",
    "- When the same initial population is used for all kernels, each kernel reaches the same steady state distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sink/Source/Bridge Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts_barplot(results, CLUSTER_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts_lineplot(results, KERNEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation(s): \n",
    "- Assuming all kernels have reached steady state, there appears to be no variation among the number of sinks, sources, and bridges for each of the kernels.\n",
    "- The number of sinks and sources increase as the number of clusters increases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geojson\n",
    "from descartes import PolygonPatch\n",
    "\n",
    "# To plot a background, convert the SHP file(s) to a geojson file\n",
    "# Use: https://mygeodata.cloud/converter/shp-to-geojson\n",
    "with open(\"STP.geojson\") as json_file:\n",
    "    json_data = geojson.load(json_file)\n",
    "\n",
    "poly = json_data['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieves the polygon coordinates for the background \n",
    "principe = { 'type' : 'MultiPolygon', 'coordinates' : poly[0]['geometry']['coordinates'] }\n",
    "sao_tome = { 'type' : 'MultiPolygon', 'coordinates' : poly[1]['geometry']['coordinates'] }\n",
    "all_data = { 'type' : 'MultiPolygon', 'coordinates' : poly[0]['geometry']['coordinates'][:] }\n",
    "all_data['coordinates'].extend(poly[1]['geometry']['coordinates'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = results[CLUSTER_NUM][KERNEL_NAME]\n",
    "cids = d.clabels()\n",
    "prps = d.results()\n",
    "\n",
    "principe_locs = cids[cids['lat'] > 1.25]\n",
    "principe_tmtx = kernels[KERNEL_NAME].iloc[principe_locs.index, principe_locs.index]\n",
    "principe_coms = prps[prps.index.isin(principe_locs['cid'].unique())]\n",
    "\n",
    "sao_tome_locs = cids[cids['lat'] < 0.50]\n",
    "sao_tome_tmtx = kernels[KERNEL_NAME].iloc[sao_tome_locs.index, sao_tome_locs.index]\n",
    "sao_tome_coms = prps[prps.index.isin(sao_tome_locs['cid'].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(principe_tmtx, principe_locs, principe_coms,\\\n",
    "          nodes_fn=lambda x: x**(1/3),\n",
    "          bordr_mu=3,\n",
    "          min_prob=0.007,\n",
    "          edges_mu=100,\n",
    "          bgrd_crd=principe,\n",
    "          bgbd_lwd=5,\n",
    "          fig_size=(10,9),\n",
    "          plt_bbar=True,\n",
    "          plt_pbar=True,\n",
    "          plt_sbar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(sao_tome_tmtx, sao_tome_locs, sao_tome_coms,\\\n",
    "          nodes_fn=lambda x: x**(1/4),\n",
    "          bordr_mu=5,\n",
    "          edges_fn=np.log10,\n",
    "          min_prob=0.009,\n",
    "          edges_mu=1,\n",
    "          bgrd_crd=sao_tome,\n",
    "          bgbd_lwd=2,\n",
    "          fig_size=(13,9),\n",
    "          plt_bbar=True,\n",
    "          plt_pbar=True,\n",
    "#           plt_sbar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
